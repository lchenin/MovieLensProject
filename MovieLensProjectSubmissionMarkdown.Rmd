---
title: "MovieLensProjectSubmission"
author: "L. Chenin"
date: "14/02/2020"
output: 
  pdf_document:
     latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This is a report on the MovieLens Project. The data set was obtained from http://files.grouplens.org/datasets/movielens/ml-10m.zip and partitioned in an edx set and a validation set by eDX Harvard Data Science Team. This data set is the basis to check the proposed predicted movie ratings and RMSE score(s), as derived from the Netflix challenge, and is targeted to be below 0.86490.

The edX course 8 material was used to take into account movie, and user effects with penalized least squares to investigate the impact on the RMSE scores. However, as the scores obtained were close to the requirement, we investigated the effect of date when movies are rated, the genres the movie is classified and the year when movie was available to check further their impacts on the RMSE scores. 

They are summarized as follows:

|method                                               |      RMSE| edX RMSE|
|:----------------------------------------------------|---------:|--------:|
|Just the average                                     | 1.0605613|1.0612018|
|Movie Effect Model                                   | 0.9439868|0.9439087|
|Movie + Effect Model                                 | 0.8666408|0.8653488|
|Regularized Movie Effect Model                       | 0.9439217|0.9438521|
|Regularized Movie + User Effect Model                | 0.8659626|0.8648201|
|Reg Movie + User + Date Effect Model                 | 0.8658438|0.8647012|
|Reg Movie + User + Date + Genres Effect Model        | 0.8655123|0.8643146|
|Reg Movie + User + Date + Genres + Year Effect Model | 0.8653194|0.8641310|

A further step of prediction was tried with the SVD and PCA analysis but remains to be worked out, as questions arised that were not solved, i.e. recompose the data frame with the predictions, apply the predictions to the test set and compute the RMSE score. Request for assistance will be posted to get hints. 

## Analysis

The analysis of the edx set shows that it has 9,000,055 observations of 6 variables, namely

- userId for 69,878 distinct users
- movieId for 10,677 distinct movies
- 9,000,055 rating distributed in 10 sequenced ratings, 0.5 to 5.0 as follows:  

| rating  | quantity  |
|:--------|-----------|
| 0.5     |    85,374 |
| 1.0     |   345,679 |
| 1.5     |   106,426 |
| 2.0     |   711,422 |
| 2.5     |   330,010 |
| 3.0     | 2,121,240 |
| 3.5     |   791,624 |
| 4.0     | 2,588,430 |
| 4.5     |   526,736 |
| 5.0     | 1,390,114 |  
   
- timestamp for 6,519,590 distinct timestamps
- title for 10,676 distinct titles
- genres for 797 distinct combinations of genres.
 
```{r MovieLens import and edx and validation dataset}
################################
# Create edx set, validation set
################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))
library(stringr)
movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId], title = as.character(title),
                genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

n_distinct(edx$movieId)

n_distinct(edx$userId)

n_distinct(edx$genres)

n_distinct(edx$timestamp)

n_distinct(edx$rating)

n_distinct(edx$title)

```
#### We check the models to implement with a data partition of edx, and the first steps of checking the movie effect, and combined movie and user effects:  

``` {r edx dataset partition for training and testing the predictions}

# let us create an additional partition of training and test sets from the provided edx datasset 

set.seed(755, sample.kind = "Rounding") #  in R 3.6 or later
test_index <- createDataPartition(y = edx$rating, times = 1,
                                  p = 0.2, list = FALSE)
train_set <- edx[-test_index,]
test_set <- edx[test_index,]

# to make sure we don't include users and movies in the test set that do not appear in 
# the training set, 
# we remove these entries using the semi_join function 
test_set <- test_set %>%  
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")

# Define the RMSE as per the Netflix challenge

RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}

# Define mu_hat, the average of all ratings

mu_hat <- mean(train_set$rating)
mu_hat

# perform a prediction with all unknown ratings equal to mu_hat

naive_rmse <- RMSE(test_set$rating, mu_hat)
naive_rmse

rmse_results <- tibble(method = "Just the average", RMSE = naive_rmse)

# compute movie effect b_i. Drop the hat of mu_hat  

mu <- mean(train_set$rating) 

movie_avgs <- train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu)) 

# predict with y_hat = mu_hat + b_i 

predicted_ratings <- mu + test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  pull(b_i)

RMSE(test_set$rating, predicted_ratings)

model_1_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie Effect Model",
                                     RMSE = model_1_rmse ))
rmse_results %>% knitr::kable()

# compute user effect b_u 

user_avgs <- train_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

# predict with mu + b_i + b_u

predicted_ratings <- test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

RMSE(test_set$rating, predicted_ratings)

model_2_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie + User Effects Model",  
                                     RMSE = model_2_rmse ))
rmse_results %>% knitr::kable()
```

#### Regularization with penalized least squares. Let’s compute these regularized estimates of b_i using  an optimal λ=  2.25. See below  for the code getting an optimal λ= 4.75 when combining movie and user effect.

``` {r penalized squares}
lambda <- 2.25
mu <- mean(train_set$rating)
movie_reg_avgs <- train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = sum(rating - mu)/(n()+lambda), n_i = n()) 

# Do we improve our results? not that much !

predicted_ratings <- test_set %>% 
  left_join(movie_reg_avgs, by = "movieId") %>%
  mutate(pred = mu + b_i) %>%
  pull(pred)

RMSE(predicted_ratings, test_set$rating) 
model_3_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Regularized Movie Effect Model",  
                                     RMSE = model_3_rmse ))

rmse_results %>% knitr::kable()
```

#### compute RMSE with λ betwwen 4.0 and 5.5 that has been found optimal at 4.75 for b_i and b_u. 

``` {r lamdas computation}
lambdas <- seq(4.0, 5.5, 0.25)
        
rmses <- sapply(lambdas, function(l){
        mu <- mean(train_set$rating)
        b_i <- train_set %>% 
        group_by(movieId) %>%
        summarize(b_i = sum(rating - mu)/(n()+l))
         
        b_u <- train_set %>% 
        left_join(b_i, by="movieId") %>%
        group_by(userId) %>%
        summarize(b_u = sum(rating - b_i - mu)/(n()+l))
          
        predicted_ratings <- test_set %>% 
           left_join(b_i, by = "movieId") %>%
           left_join(b_u, by = "userId") %>%
           mutate(pred = mu + b_i + b_u) %>%
          pull(pred)
          
         return(RMSE(predicted_ratings, test_set$rating))
       })

```
#### we plot the lambdas

``` {r lambdas, fig1, fig.width=7, fig.height=6, echo=FALSE, message=FALSE, include=TRUE, fig.cap="Plot optimal lambda"}

qplot(lambdas, rmses)  

```   
    
####  For the full model, the optimal  λ is:

``` {r compute regularized effect for movie and user}

lambda <- lambdas[which.min(rmses)]
lambda

lambda <- 4.75

mu <- mean(train_set$rating)

b_i <- train_set %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

b_u <- train_set %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))

predicted_ratings <- test_set %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

RMSE(predicted_ratings, test_set$rating)

model_4_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Regularized Movie + User Effect Model",  
                                     RMSE = model_4_rmse ))
rmse_results %>% knitr::kable()
```

#### to access the date we use the lubridate package on the timestamp to get the weeks when the movies are rated:

``` {r date effect}

# Date effect 
# refine by adding  d_u, the effect of the date the movie was watched with groupings per week

library("lubridate")

test_set <- test_set  %>% mutate(date = round_date(as_datetime(timestamp), unit = "week"))
train_set <- train_set %>% mutate(date = round_date(as_datetime(timestamp), unit = "week"))

# plot the average rating for each week against date 

```
#### plot date versus rating

``` {r date rating plot, fig2, fig.width=7, fig.height=6, echo=FALSE, message=FALSE,include=TRUE, fig.cap="Rating versus date"}

train_set %>% group_by(date) %>% 
  summarize(rating = mean(rating)) %>% 
  ggplot(aes(date, rating)) +
  geom_point() +
  geom_smooth()

```

#### compute the date effect

``` {r compute date effect}

mu <- mean(train_set$rating)

d_u <- train_set %>%
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by="userId") %>%
  group_by(date) %>%
  summarize(d_u = sum(rating - b_i - b_u -mu)/(n() + lambda))

predicted_ratings <- 
  test_set %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(d_u, by ="date") %>%
  mutate(pred = mu + b_i + b_u + d_u) %>%
  pull(pred)

RMSE(predicted_ratings, test_set$rating)

model_5_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Reg Movie + User + Date Effect Model",  
                                     RMSE = model_5_rmse ))
rmse_results %>% knitr::kable()

```

#### Genres Effect
#### plot the error bar plots of the average and standard error for each category of genres as there are 796 genres we limit to a sample of 80 genres, or 10%.

``` {r genres plot, fig3, fig.width=7, fig.height=6, echo=FALSE, message=FALSE,include=TRUE, fig.cap="Average & std error versus 80 genres"}

train_set %>% group_by(genres) %>% 
  summarize(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n()), ) %>%
  filter(n >= 1000) %>%
  sample_n(., 80) %>%                           
  mutate(genres = reorder(genres, avg)) %>% 
  ggplot(aes(x= genres, y = avg, ymin = avg -2*se, ymax = avg + 2*se)) +
  geom_point() +
  geom_errorbar() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

#### compute genres effect

``` {r compute genres effect}

# final computation with optimal  λ =4.75

lambda <- 4.75

g_u <- train_set %>%
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by="userId") %>%
  left_join(d_u, by="date") %>%
  group_by(genres) %>%
  summarize(g_u = sum(rating - d_u - b_i - b_u -mu)/(n() + lambda))

predicted_ratings <- 
  test_set %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(d_u, by ="date") %>%
  left_join(g_u, by = "genres") %>%
  mutate(pred = mu + b_i + b_u + d_u + g_u) %>%
  pull(pred)

RMSE(predicted_ratings, test_set$rating)

model_6_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Reg Movie + User + Date + Genres Effect Model",  
                                     RMSE = model_6_rmse ))
rmse_results %>% knitr::kable()
```

#### Year effect. We investigate effect of year when movie is issued. Extract the year and mutate it.


``` {r year movie was issued effect}

test_set <- test_set  %>% mutate(year = str_extract(str_extract(test_set$title, "\\(\\d{4}\\)"), "\\d{4}"))
train_set <- train_set  %>% mutate(year = str_extract(str_extract(train_set$title, "\\(\\d{4}\\)"), "\\d{4}"))
```

#### plot the year versus average rating

``` {r year rating plot, fig4, fig.width=7, fig.height=6, echo=FALSE, message=FALSE,include=TRUE, fig.cap="Rating average & std error versus year"}

train_set %>% group_by(year) %>% 
  summarize(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n())) %>% 
  ggplot(aes(x= year, y = avg, ymin = avg -2*se, ymax = avg + 2*se)) +
  geom_point() +
  geom_errorbar() +
  theme(axis.text.x = element_text(angle = 90, size = 6, hjust = 1))

```

#### plot the number of movies rated per year

``` {r year number of movies rated, fig5, fig.width=7, fig.height=6, echo=FALSE, message=FALSE,include=TRUE, fig.cap="Number of movies, median & interquartile range versus year"}

train_set %>% group_by(year,movieId) %>%
  summarize(n = n()) %>%
  qplot(year, n, data = ., geom = "boxplot") +
  coord_trans(y = "sqrt") +
  theme(axis.text.x = element_text(angle = 90, size = 6, hjust = 1))
``` 

#### compute year effect

``` {r year effect, y_u}

y_u <- train_set %>%
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by="userId") %>%
  left_join(d_u, by="date") %>%
  left_join(g_u, by="genres") %>%
  group_by(year) %>%
  summarize(y_u = sum(rating -g_u - d_u - b_i - b_u -mu)/(n() + lambda))

predicted_ratings <- 
  test_set %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(d_u, by ="date") %>%
  left_join(g_u, by = "genres") %>%
  left_join(y_u, by = "year") %>%
  mutate(pred = mu + b_i + b_u + d_u + g_u + y_u) %>%
  pull(pred)

RMSE(predicted_ratings, test_set$rating)

model_7_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                data_frame(method="Reg Movie + User + Date + Genres + Year Effect Model",  RMSE = model_7_rmse ))
rmse_results %>% knitr::kable()  
```

#### issue the final predictions for the edx and validation data sets and compute the final RMSE scores

``` {r edx and validation dataset RMSE scores}

# Define the RMSE as per the Netflix challenge

RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}

# Define mu_hat, the average of all ratings

mu_hat <- mean(edx$rating)
mu_hat

# perform a prediction with all unknown ratings equal to mu_hat

naive_rmse <- RMSE(validation$rating, mu_hat)
naive_rmse

rmse_results_f <- tibble(method = "Just the average", edX_RMSE = naive_rmse)

# compute movie effect b_i. Drop the hat of mu_hat  

mu <- mean(edx$rating) 
movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu)) 

# predict with y_hat = mu_hat + b_i 

predicted_ratings <- mu + validation %>% 
  left_join(movie_avgs, by='movieId') %>%
  pull(b_i)

RMSE(validation$rating, predicted_ratings)

model_1_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results_f <- bind_rows(rmse_results_f,
                          data_frame(method="Movie Effect Model",
                                     edX_RMSE = model_1_rmse ))
rmse_results_f %>% knitr::kable()

# compute user effect b_u 

user_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

# predict with y_hat = mu_hat + b_i + b_u

predicted_ratings <- validation %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

RMSE(validation$rating, predicted_ratings)

model_2_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results_f <- bind_rows(rmse_results_f,
                          data_frame(method="Movie + User Effects Model",  
                                    edX_RMSE = model_2_rmse ))
rmse_results_f %>% knitr::kable()

# Regularization

# Let’s compute these regularized estimates of b_i using  λ=  2.25 

lambda <- 2.25
mu <- mean(edx$rating)
movie_reg_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = sum(rating - mu)/(n()+lambda), n_i = n()) 


# Do we improve our results? not much

predicted_ratings <- validation %>% 
  left_join(movie_reg_avgs, by = "movieId") %>%
  mutate(pred = mu + b_i) %>%
  pull(pred)
RMSE(predicted_ratings, validation$rating) 

model_3_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results_f <- bind_rows(rmse_results_f,
                          data_frame(method="Regularized Movie Effect Model",  
                                     edX_RMSE = model_3_rmse ))

rmse_results_f %>% knitr::kable()


# compute RMSE with λ optimal at 4.75

lambda <- 4.75

mu <- mean(edx$rating)

b_i <- edx %>% 
  group_by(movieId) %>%
  summarize(b_i = sum(rating - mu)/(n()+lambda))

b_u <- edx %>% 
  left_join(b_i, by="movieId") %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - b_i - mu)/(n()+lambda))

predicted_ratings <- 
  validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

RMSE(predicted_ratings, validation$rating)

model_4_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results_f <- bind_rows(rmse_results_f,
                          data_frame(method="Regularized Movie + User Effect Model",  
                                     edX_RMSE = model_4_rmse ))
rmse_results_f %>% knitr::kable()

# refine by adding  d_u with groupings per week 

validation <- validation %>% mutate(date = round_date(as_datetime(timestamp), unit = "week"))
edx <- edx %>% mutate(date = round_date(as_datetime(timestamp), unit = "week"))


d_u <- edx %>%
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by="userId") %>%
  group_by(date) %>%
  summarize(d_u = sum(rating - b_i - b_u -mu)/(n() + lambda))

predicted_ratings <- 
  validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(d_u, by ="date") %>%
  mutate(pred = mu + b_i + b_u + d_u ) %>%
  pull(pred)

RMSE(predicted_ratings, validation$rating)

model_5_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results_f <- bind_rows(rmse_results_f,
                          data_frame(method="Reg Movie + User + Date Effect Model",  
                                     edX_RMSE = model_5_rmse ))
rmse_results_f %>% knitr::kable()

# refine by adding  g_u with genres

g_u <- edx %>%
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by="userId") %>%
  left_join(d_u, by="date") %>%
  group_by(genres) %>%
  summarize(g_u = sum(rating - d_u - b_i - b_u -mu)/(n() + lambda))

predicted_ratings <- 
  validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(d_u, by ="date") %>%
  left_join(g_u, by = "genres") %>%
  mutate(pred = mu + b_i + b_u + d_u + g_u) %>%
  pull(pred)

RMSE(predicted_ratings, validation$rating)

model_6_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results_f <- bind_rows(rmse_results_f,
                          data_frame(method="Reg Movie + User + Date + Genres Effect Model",  
                                     edX_RMSE = model_6_rmse ))
rmse_results_f %>% knitr::kable()

# Year effect

# investigate effect of year when movie is issued. Extract the year and mutate it.

validation <- validation  %>% mutate(year = str_extract(str_extract(validation$title, "\\(\\d{4}\\)"), "\\d{4}"))
edx <- edx  %>% mutate(year = str_extract(str_extract(edx$title, "\\(\\d{4}\\)"), "\\d{4}"))

# compute year effect

y_u <- edx %>%
  left_join(b_i, by="movieId") %>%
  left_join(b_u, by="userId") %>%
  left_join(d_u, by="date") %>%
  left_join(g_u, by="genres") %>%
  group_by(year) %>%
  summarize(y_u = sum(rating -g_u - d_u - b_i - b_u -mu)/(n() + lambda))

predicted_ratings <- 
  validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  left_join(d_u, by ="date") %>%
  left_join(g_u, by = "genres") %>%
  left_join(y_u, by = "year") %>%
  mutate(pred = mu + b_i + b_u + d_u + g_u + y_u) %>%
  pull(pred)

RMSE(predicted_ratings, validation$rating)

model_7_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results_f <- bind_rows(rmse_results_f,
                          data_frame(method="Reg Movie + User + Date + Genres + Year Effect Model",  
                                     edX_RMSE = model_7_rmse ))
rmse_results_f %>% knitr::kable()
```

#### investigate SVD and PCA with the following piece of code

``` {r SVD and PCA}

# Matrix factorization

# edit a workable subset of the train_set as the whole train_set failed.

train_mat <- train_set %>%
  group_by(movieId) %>% 
  filter(n() >= 1000) %>% ungroup() %>%
  group_by(userId) %>% 
  filter(n() >= 100) %>% ungroup() 

# assemble the matrix

y <- train_mat %>% 
  select(userId, movieId, rating) %>%
  spread(movieId, rating) %>%
  as.matrix()

#  add row names and column names

rownames(y) <- y[,1]
y <- y[,-1]

# get distinct movieId and title

movie_titles <- train_set %>%
  select(movieId, title) %>% 
  distinct()

colnames(y) <- with(movie_titles, title[match(colnames(y), movieId)])

# convert y to residuals substracting b_i and b_u

y <- sweep(y, 2, colMeans(y, na.rm = TRUE))
y <- sweep(y, 1, rowMeans(y, na.rm = TRUE))

# compute the decomposition making the residuals with NAs equal to 0.

y[is.na(y)] <- 0

pca <- prcomp(y)   # command failed as "Error: cannot allocate vector of size 3.4 Gb but worked with filter n >1000 movies and n > 100 users

dim(pca$rotation)

dim(pca$x)
```


#### plot variability for the vectors


``` {r variability, fig6, fig.width=7, fig.height=6, echo=FALSE, message=FALSE,include=TRUE, fig.cap="Principal Component variability"}
qplot(1:nrow(pca$rotation), pca$sdev, xlab ="PC")
```

#### compute SVD decomposition of y


``` {r  SVD decomposition }

s <- svd(y)
names(s)

# What proportion of the total variability is explained by the first 1,500 columns of  YV ?

sum(s$d[1:1500]^2) / sum(s$d^2)   # to get to 98% !!!
 
y_hat <- with(s,sweep(u[, 1:1500], 2, d[1:1500], FUN="*") %*% t(v[, 1:1500]))


#### there remains to convert this matrix to the useful dataframe of movie, users and ratings to arrive to a prediction to be made on a test_matrix or vector with the RMSE score. 

# call to ggrepel

library(ggrepel)


pcs <- data.frame(pca$rotation, name = colnames(y))

```

#### plot clusters 

``` {r plot possible movie clusters, fig8, fig.width=7, fig.height=6, echo=FALSE, message=FALSE,include=TRUE, fig.cap="First two components movies trends"}

pcs %>%  ggplot(aes(PC1, PC2)) + geom_point() + 
  geom_text_repel(aes(PC1, PC2, label=name),
                  data = filter(pcs, 
                         PC1 < -0.1 | PC1 > 0.1 | PC2 < -0.075 | PC2 > 0.1))
```

#### identify 10 movies in the possible clusters out of the central cloud

``` {r }

pcs %>% select(name, PC1) %>% arrange(PC1) %>% slice(1:10)

pcs %>% select(name, PC1) %>% arrange(desc(PC1)) %>% slice(1:10)

pcs %>% select(name, PC2) %>% arrange(PC2) %>% slice(1:10)

pcs %>% select(name, PC2) %>% arrange(desc(PC2)) %>% slice(1:10)
```
